
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the Enviromental Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHARED_FS = 'tpushare'\n",
    "MOUNT_POINT = '/mnt/common'\n",
    "TPU_POD_NAME = 'nyc-tpu-v3-32' \n",
    "NFS_IP = '10.224.68.26'\n",
    "BUILD = '5e452b42-a97c-40da-9a1a-5f2a5fc6ba34'\n",
    "PYTORCH_PROJ_NAME='pytorch-tpu-nfs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load data from GCS bucket "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCS_DATASET='gs://tpu-demo-eu/dataset/*'\n",
    "!if [ -d \"$MOUNT_POINT/data\" ]; then echo \"using existing $MOUNT_POINT/data directory\"; else sudo mkdir -p $MOUNT_POINT/data && sudo gsutil -m cp -r $GCS_DATASET $MOUNT_POINT/data/; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Download RoBERTa code from repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CODE_REPO='https://github.com/taylanbil/fairseq.git'\n",
    "BRANCH='roberta-tpu'\n",
    "!if [ -d \"$MOUNT_POINT/code\" ]; then echo \"using existing $MOUNT_POINT/code directory\"; else sudo mkdir -p $MOUNT_POINT/code && sudo git clone $CODE_REPO $MOUNT_POINT/code/; fi\n",
    "!cd $MOUNT_POINT/code && git fetch && git checkout $BRANCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Set the execution Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logfile = \"$(date +%Y%m%d)-roberta-podrun-$1.txt\"\n",
    "nshards = 1\n",
    "num_cores = 8\n",
    "data_path = \"$MOUNT_POINT/data\" \n",
    "DATABIN = '/mnt/common/data/shard0'\n",
    "checkpoints_out = MOUNT_POINT+'/checkpoints/checkpoints-roberta'+BUILD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Execute torch_xla.distributed.xla_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m torch_xla.distributed.xla_dist --tpu=$TPU_POD_NAME \\\n",
    "\t--docker-run-flag=--shm-size=120GB \\\n",
    "\t--docker-run-flag=--rm=true \\\n",
    "\t--docker-run-flag=--volume=$SHARED_FS:$MOUNT_POINT \\\n",
    "\t--env=XLA_USE_BF16=1  \\\n",
    "\t--docker-image=gcr.io/$PYTORCH_PROJ_NAME/xla:$BUILD -- python $MOUNT_POINT/code/train.py \\\n",
    "\t$DATABIN \\\n",
    "\t--save-dir $checkpoints_out \\\n",
    "\t--arch roberta_large \\\n",
    "\t--optimizer adam \\\n",
    "\t--adam-betas \"(0.9, 0.98)\" \\\n",
    "\t--adam-eps 1e-06 \\\n",
    "\t--clip-norm 1.0 \\\n",
    "\t--lr-scheduler polynomial_decay \\\n",
    "\t--lr 0.0004 \\\n",
    "\t--warmup-updates 15000 \\\n",
    "\t--max-update 1500000 \\\n",
    "\t--log-format json \\\n",
    "\t--log-interval 10 \\\n",
    "\t--skip-invalid-size-inputs-valid-test \\\n",
    "\t--task multilingual_masked_lm \\\n",
    "\t--criterion masked_lm \\\n",
    "\t--dropout 0.1 \\\n",
    "\t--attention-dropout 0.1 \\\n",
    "\t--weight-decay 0.01 \\\n",
    "\t--sample-break-mode complete \\\n",
    "\t--tokens-per-sample 512 \\\n",
    "\t--total-num-update 1500000 \\\n",
    "\t--multilang-sampling-alpha 0.7 \\\n",
    "\t--no-epoch-checkpoints \\\n",
    "\t--save-interval-updates 3000 \\\n",
    "\t--validate-interval 5000 \\\n",
    "\t--num-workers 1 \\\n",
    "\t--update-freq `expr 4096 / 8` \\\n",
    "\t--valid-subset=valid \\\n",
    "\t--train-subset=train \\\n",
    "\t--input_shapes 2x512 \\\n",
    "\t--num_cores=8 \\\n",
    "\t--metrics_debug \\\n",
    "\t--suppress_loss_report \\\n",
    "\t--log_steps=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
